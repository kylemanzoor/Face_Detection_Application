{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #open-cv module\n",
    "import matplotlib.pyplot as plt #plot where the image will be placed on because it performs greta imaging\n",
    "%matplotlib inline \n",
    "#keeps image between x and y axises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HAAR Cascade File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml') #cascade file that is hard casted and saved as face. In the parentheses, the xml file is there since this file helps determine the faces detected in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('imgFC.jpg') #the cascade file reads the image we upload\n",
    "# convert to RGB\n",
    "img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #Initially, cv2 reads the image as BGR. So, we convert the faces in the image into RGB\n",
    "plt.imshow(img_rgb) #the plot shows the image that was converted to RGB color scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to gray scale image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #converts the image color scheme from BGR (so the original image) to gray\n",
    "plt.imshow(gray, cmap ='gray') #the plot shows the gray image. Have to use cmap parameter because it helps convert the image into a gray color. Without it, the image will show a mix of different colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4, minSize=(30,30)) #the cascade file detects the faces in the image using multiple parameters. Uses the gray image, scaleFactor which deals with different sizes of faces, minNeighbors which is used to tell us how many faces can be near to a single face, and minSize so the minimum height and width the face can have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(faces) #prints the number of faces detected in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the faces in the image\n",
    "for(x, y, w, h) in faces: #figures out each faces x value, y value, width, and height\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2) #create the shape of the detector as a rectangle using the original image, the start point of the face, the end point of the face, green color for the rectangle, and the thickness of the line \n",
    "cv2.imshow(\"Faces\", image) #opens a new window. Faces is the title and we use the original image\n",
    "cv2.waitKey(0) #if a key has been pressed, it will close the window"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
